{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "from tools import normalize_img, gen_dx_bx, img_transform\n",
    "from models import compile_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model weight path\n",
    "modelf = '/Users/navyarao/Desktop/projects/lift-splat-shoot/weights/model300.pt'\n",
    "input_path = '/Users/navyarao/Desktop/projects/sim/LSSCAM/1/*.jpeg'\n",
    "output_path = '/Users/navyarao/Desktop/projects/lift-splat-shoot/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "gpuid=0\n",
    "viz_train=False\n",
    "video_output=True\n",
    "max_frames=-1\n",
    "channel=1\n",
    "H=900\n",
    "W=1600\n",
    "resize_lim=(0.193, 0.225)\n",
    "final_dim=(128, 352)\n",
    "bot_pct_lim=(0.0, 0.22)\n",
    "rot_lim=(-5.4, 5.4)\n",
    "rand_flip=True\n",
    "\n",
    "xbound=[-50.0, 50.0, 0.5]\n",
    "ybound=[-50.0, 50.0, 0.5]\n",
    "zbound=[-10.0, 10.0, 20.0]\n",
    "dbound=[4.0, 45.0, 1.0]\n",
    "\n",
    "bsz=1\n",
    "nworkers=0\n",
    "    \n",
    "grid_conf = {\n",
    "    'xbound': xbound,\n",
    "    'ybound': ybound,\n",
    "    'zbound': zbound,\n",
    "    'dbound': dbound,\n",
    "}\n",
    "\n",
    "data_aug_conf = {\n",
    "    'resize_lim': resize_lim,\n",
    "    'final_dim': final_dim,\n",
    "    'rot_lim': rot_lim,\n",
    "    'H': H, 'W': W,\n",
    "    'rand_flip': rand_flip,\n",
    "    'bot_pct_lim': bot_pct_lim,\n",
    "    'cams': ['CAM_FRONT'],\n",
    "    'Ncams': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_augmentation():\n",
    "    H, W = data_aug_conf['H'], data_aug_conf['W']\n",
    "    fH, fW = data_aug_conf['final_dim']\n",
    "    resize = max(fH/H, fW/W)\n",
    "    resize_dims = (int(W*resize), int(H*resize))\n",
    "    newW, newH = resize_dims\n",
    "    crop_h = int((1 - np.mean(data_aug_conf['bot_pct_lim']))*newH) - fH\n",
    "    crop_w = int(max(0, newW - fW) / 2)\n",
    "    crop = (crop_w, crop_h, crop_w + fW, crop_h + fH)\n",
    "    flip = False\n",
    "    rotate = 0\n",
    "    return resize, resize_dims, crop, flip, rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "loading /Users/navyarao/Desktop/projects/lift-splat-shoot/weights/model300.pt\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu') #if gpuid < 0 else torch.device(f'cuda:{gpuid}')\n",
    "\n",
    "model = compile_model(grid_conf, data_aug_conf, outC=3)\n",
    "print('loading', modelf)\n",
    "model.load_state_dict(torch.load(modelf, map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "#Ego pose\n",
    "dx, bx, _ = gen_dx_bx(grid_conf['xbound'], grid_conf['ybound'], grid_conf['zbound'])\n",
    "dx, bx = dx[:2].numpy(), bx[:2].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rots = []\n",
    "rot = torch.tensor([[ 0.0103,  0.0084,  0.9999],\n",
    "                    [-0.9999,  0.0123,  0.0102],\n",
    "                    [-0.0122, -0.9999,  0.0086]])\n",
    "rots.append(rot) \n",
    "rots = torch.stack(rots)\n",
    "\n",
    "tran1 = []\n",
    "trans = []\n",
    "tran = torch.tensor([ 1.7220,  0.0048,  1.4949])\n",
    "tran1.append(tran)\n",
    "tran1 = torch.stack(tran1)\n",
    "trans.append(tran1)\n",
    "trans = torch.stack(trans)\n",
    "\n",
    "intrins = []\n",
    "intrin = torch.tensor([[1.2528e+03, 0.0000e+00, 8.2659e+02],\n",
    "                    [0.0000e+00, 1.2528e+03, 4.6998e+02],\n",
    "                    [0.0000e+00, 0.0000e+00, 1.0000e+00]])\n",
    "intrins.append(intrin)\n",
    "intrins = torch.stack(intrins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = '/Users/navyarao/Desktop/projects/sim/LSSCAM/1/CAM1_000143.jpeg'\n",
    "imgs = []\n",
    "img1 = []\n",
    "post_rots = []\n",
    "post_trans = []\n",
    "post_trans1 = []\n",
    "post_rot = torch.eye(2)\n",
    "post_tran = torch.zeros(2)\n",
    "\n",
    "img = Image.open(input_image)\n",
    "# img = np.array(img)\n",
    "# img = img[:,:,:3]\n",
    "# img = Image.fromarray(img)\n",
    "resize, resize_dims, crop, flip, rotate = sample_augmentation()\n",
    "img, post_rot2, post_tran2 = img_transform(img, post_rot, post_tran,\n",
    "                                            resize=resize,\n",
    "                                            resize_dims=resize_dims,\n",
    "                                            crop=crop,\n",
    "                                            flip=flip,\n",
    "                                        rotate=rotate,\n",
    "                                            )\n",
    "\n",
    "img1.append(normalize_img(img))\n",
    "img1 = torch.stack(img1)\n",
    "imgs.append(img1)\n",
    "imgs = torch.stack(imgs)\n",
    "\n",
    "post_rot = torch.eye(3)\n",
    "post_rot[:2, :2] = post_rot2\n",
    "post_rots.append(post_rot)\n",
    "post_rots = torch.stack(post_rots)\n",
    "\n",
    "post_tran = torch.zeros(3)\n",
    "post_tran[:2] = post_tran2\n",
    "post_trans1.append(post_tran)\n",
    "post_trans1 = torch.stack(post_trans1)\n",
    "post_trans.append(post_trans1)\n",
    "post_trans = torch.stack(post_trans)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(imgs.to(device),\n",
    "        rots.to(device),\n",
    "        trans.to(device),\n",
    "        intrins.to(device),\n",
    "        post_rots.to(device),\n",
    "        post_trans.to(device),\n",
    "        )\n",
    "    out = out.sigmoid().cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0,1] *= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[140.0577, 135.2525, 145.1121,  ...,  83.3655,  75.5490,  74.3190],\n",
       "        [163.3384, 145.4908, 153.3367,  ...,  71.0115,  65.3056,  77.0661],\n",
       "        [156.8511, 138.4378, 150.3618,  ...,  75.2628,  68.0182,  74.3101],\n",
       "        ...,\n",
       "        [143.6554, 156.5810, 157.4011,  ...,   0.9357,   2.5771,   1.6609],\n",
       "        [140.5839, 146.5888, 152.6808,  ...,   1.8795,   4.6681,   3.1703],\n",
       "        [122.3082, 134.0489, 136.7535,  ...,   5.9921,  11.1088,   9.4798]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img = transforms.ToPILImage()(out[0,1]).convert(\"RGB\")\n",
    "pil_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image load and operations from here\n",
    "def process_image_data(input_image):\n",
    "    imgs = []\n",
    "    img1 = []\n",
    "    post_rots = []\n",
    "    post_trans = []\n",
    "    post_trans1 = []\n",
    "    post_rot = torch.eye(2)\n",
    "    post_tran = torch.zeros(2)\n",
    "\n",
    "    img = Image.open(input_image)\n",
    "    # img = np.array(img)\n",
    "    # img = img[:,:,:3]\n",
    "    # img = Image.fromarray(img)\n",
    "    resize, resize_dims, crop, flip, rotate = sample_augmentation()\n",
    "    img, post_rot2, post_tran2 = img_transform(img, post_rot, post_tran,\n",
    "                                                resize=resize,\n",
    "                                                resize_dims=resize_dims,\n",
    "                                                crop=crop,\n",
    "                                                flip=flip,\n",
    "                                            rotate=rotate,\n",
    "                                                )\n",
    "\n",
    "    img1.append(normalize_img(img))\n",
    "    img1 = torch.stack(img1)\n",
    "    imgs.append(img1)\n",
    "    imgs = torch.stack(imgs)\n",
    "\n",
    "    post_rot = torch.eye(3)\n",
    "    post_rot[:2, :2] = post_rot2\n",
    "    post_rots.append(post_rot)\n",
    "    post_rots = torch.stack(post_rots)\n",
    "\n",
    "    post_tran = torch.zeros(3)\n",
    "    post_tran[:2] = post_tran2\n",
    "    post_trans1.append(post_tran)\n",
    "    post_trans1 = torch.stack(post_trans1)\n",
    "    post_trans.append(post_trans1)\n",
    "    post_trans = torch.stack(post_trans)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(imgs.to(device),\n",
    "            rots.to(device),\n",
    "            trans.to(device),\n",
    "            intrins.to(device),\n",
    "            post_rots.to(device),\n",
    "            post_trans.to(device),\n",
    "            )\n",
    "        out = out.sigmoid().cpu()\n",
    "\n",
    "    \n",
    "\n",
    "    img_final = torch.cat((out[0,0],out[0,1],out[0,2]),1)\n",
    "    # print(img_final.shape)\n",
    "    \n",
    "    pil_image = transforms.ToPILImage()(img_final).convert(\"RGB\")\n",
    "    \n",
    "    return pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = glob.glob(input_path)\n",
    "for img in imgs:\n",
    "    print(img)\n",
    "    name = output_path + img.split('/')[-1].split('.')[0] + '.png'\n",
    "    bev_image = process_image_data(img)\n",
    "    bev_image.save(name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2006520b7ee4c0b8735dd89f87fe6d9b8c0870929f30f436aaef8bc1229d0e96"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('lss': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
