{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import ComputeTarget\n",
    "\n",
    "# name for your cluster\n",
    "cpu_cluster_name = \"general\"\n",
    "\n",
    "# check if cluster already exists\n",
    "cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "print('Found existing cluster, use it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "#env = Environment('lss')\n",
    "#env.docker.base_dockerfile = './Dockerfile' # path to your dockerfile\n",
    "env = Environment.get(ws, 'lss', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "ds = ws.datastores['mini']\n",
    "mini = Dataset.File.from_files(path=(ds, '/'))\n",
    "\n",
    "ds = ws.datastores['maps']\n",
    "maps = Dataset.File.from_files(path=(ds, '/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "\n",
    "def_blob_store = ws.get_default_datastore()\n",
    "output = OutputFileDatasetConfig(destination=(def_blob_store, 'sample/outputmodel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<azureml.data.dataset_consumption_config.DatasetConsumptionConfig object at 0x00000275C2D88AC8>, <azureml.data.dataset_consumption_config.DatasetConsumptionConfig object at 0x00000275C2D92088>, <azureml.data.output_dataset_config.OutputFileDatasetConfig object at 0x00000275C06216C8>]\n",
      "Run(Experiment: test2,\n",
      "Id: test2_1633928043_9fbffbb5,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Preparing)\n",
      "RunId: test2_1633928043_9fbffbb5\n",
      "Web View: https://ml.azure.com/runs/test2_1633928043_9fbffbb5?wsid=/subscriptions/aab48da9-d313-43b6-a34e-5f6def1a9246/resourcegroups/PilotierA/workspaces/PilotierA&tid=7a5d1346-2f6f-43ed-a996-c114a2c559a5\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: test2_1633928043_9fbffbb5\n",
      "Web View: https://ml.azure.com/runs/test2_1633928043_9fbffbb5?wsid=/subscriptions/aab48da9-d313-43b6-a34e-5f6def1a9246/resourcegroups/PilotierA/workspaces/PilotierA&tid=7a5d1346-2f6f-43ed-a996-c114a2c559a5\n",
      "\n",
      "Warnings:\n",
      "This run is using a new job runtime with improved performance and error reporting. The logs from your script are in user_logs/std_log.txt. Please let us know if you run into any issues, and if you would like to opt-out, please add the environment variable AZUREML_COMPUTE_USE_COMMON_RUNTIME to the environment variables section of the job and set its value to the string \"false\"\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'test2_1633928043_9fbffbb5',\n",
       " 'target': 'general',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-10-11T04:54:06.212943Z',\n",
       " 'endTimeUtc': '2021-10-11T04:55:47.974825Z',\n",
       " 'services': {},\n",
       " 'warnings': [{'message': 'This run is using a new job runtime with improved performance and error reporting. The logs from your script are in user_logs/std_log.txt. Please let us know if you run into any issues, and if you would like to opt-out, please add the environment variable AZUREML_COMPUTE_USE_COMMON_RUNTIME to the environment variables section of the job and set its value to the string \"false\"'}],\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '05cd4861-6e14-4d9e-b066-b9c075cc4ff3',\n",
       "  'azureml.git.repository_uri': 'https://github.com/pilotier/lift-splat-shoot.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/pilotier/lift-splat-shoot.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '25366b3c0b809a200a3452e0801f60160903d91d',\n",
       "  'mlflow.source.git.commit': '25366b3c0b809a200a3452e0801f60160903d91d',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '34b0e52b-baa7-4b39-b5e0-0a5f3ada28f1'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__c48413e8', 'mechanism': 'Mount', 'pathOnCompute': 'mini'}}, {'dataset': {'id': 'e98407ef-a6e0-4db0-b7a0-f855422db525'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__02776c2c', 'mechanism': 'Mount', 'pathOnCompute': 'maps'}}],\n",
       " 'outputDatasets': [{'identifier': {'savedId': 'a321e684-55e3-4d63-a5fb-1d424ab94ac9'},\n",
       "   'outputType': 'RunOutput',\n",
       "   'outputDetails': {'outputName': 'output_f8644957'},\n",
       "   'dataset': {\n",
       "     \"source\": [\n",
       "       \"('workspaceblobstore', 'sample/outputmodel')\"\n",
       "     ],\n",
       "     \"definition\": [\n",
       "       \"GetDatastoreFiles\"\n",
       "     ],\n",
       "     \"registration\": {\n",
       "       \"id\": \"a321e684-55e3-4d63-a5fb-1d424ab94ac9\",\n",
       "       \"name\": null,\n",
       "       \"version\": null,\n",
       "       \"workspace\": \"Workspace.create(name='PilotierA', subscription_id='aab48da9-d313-43b6-a34e-5f6def1a9246', resource_group='PilotierA')\"\n",
       "     }\n",
       "   }}],\n",
       " 'runDefinition': {'script': 'train_az.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['DatasetConsumptionConfig:input__c48413e8',\n",
       "   'DatasetConsumptionConfig:input__02776c2c',\n",
       "   'DatasetOutputConfig:output_f8644957'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'general',\n",
       "  'dataReferences': {},\n",
       "  'data': {'input__c48413e8': {'dataLocation': {'dataset': {'id': '34b0e52b-baa7-4b39-b5e0-0a5f3ada28f1',\n",
       "      'name': None,\n",
       "      'version': None},\n",
       "     'dataPath': None,\n",
       "     'uri': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'input__c48413e8',\n",
       "    'pathOnCompute': 'mini',\n",
       "    'overwrite': False,\n",
       "    'options': None},\n",
       "   'input__02776c2c': {'dataLocation': {'dataset': {'id': 'e98407ef-a6e0-4db0-b7a0-f855422db525',\n",
       "      'name': None,\n",
       "      'version': None},\n",
       "     'dataPath': None,\n",
       "     'uri': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'input__02776c2c',\n",
       "    'pathOnCompute': 'maps',\n",
       "    'overwrite': False,\n",
       "    'options': None}},\n",
       "  'outputData': {'output_f8644957': {'outputLocation': {'dataset': None,\n",
       "     'dataPath': {'datastoreName': 'workspaceblobstore',\n",
       "      'relativePath': 'sample/outputmodel'},\n",
       "     'uri': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'additionalOptions': {'pathOnCompute': None,\n",
       "     'registrationOptions': {'name': None,\n",
       "      'description': None,\n",
       "      'tags': None,\n",
       "      'datasetRegistrationOptions': {'additionalTransformation': None}},\n",
       "     'uploadOptions': None,\n",
       "     'mountOptions': {'disableMetadataCache': 'False'}},\n",
       "    'environmentVariableName': None}},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'lss',\n",
       "   'version': 'Autosave_2021-10-10T04:11:16Z_bf81123e',\n",
       "   'python': {'interpreterPath': None,\n",
       "    'userManagedDependencies': True,\n",
       "    'condaDependencies': None,\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {},\n",
       "   'docker': {'baseImage': None,\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': 'FROM pytorch/pytorch:1.8.1-cuda11.1-cudnn8-runtime\\r\\n\\r\\nRUN apt update -y\\r\\nRUN apt install gcc -y\\r\\nRUN pip install nuscenes-devkit tensorboardX efficientnet_pytorch==0.7.0\\r\\nRUN apt install ffmpeg libsm6 libxext6  -y',\n",
       "    'baseImageRegistry': None,\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None,\n",
       "   'location': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {},\n",
       " 'submittedBy': 'Ibrahim Abdulhafiz'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "from azureml.core import Experiment\n",
    "\n",
    "#arg = \"python main.py multi_train trainval --logdir=./run --gpuid=-1\".split().extend([ \"--dataroot=\"+mini.as_mount(), \"--map_folder=\"+maps.as_mount() ])\n",
    "arguments=[mini.as_mount('mini'), maps.as_mount('maps'), output]\n",
    "print(arguments)\n",
    "config = ScriptRunConfig(source_directory='..',\n",
    "                            script='train_az.py',\n",
    "                            compute_target=cpu_cluster,\n",
    "                            environment=env,\n",
    "                            arguments=arguments\n",
    "                            )\n",
    "\n",
    "exp = Experiment(ws, 'test2')\n",
    "run = exp.submit(config)\n",
    "print(run)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config)\n",
    "print(run)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.tensorboard import Tensorboard\n",
    "\n",
    "tb = Tensorboard([run])\n",
    "\n",
    "# If successful, start() returns a string with the URI of the instance.\n",
    "tb.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After your job completes, be sure to stop() the streaming otherwise it will continue to run. \n",
    "tb.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33368/2052914303.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgenerate_video_from_imgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgenerate_video_from_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../output\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.tools import generate_video_from_imgs\n",
    "\n",
    "generate_video_from_imgs(\"/output\", \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.py',\n",
       " 'explore.py',\n",
       " 'models.py',\n",
       " 'tools.py',\n",
       " 'train.py',\n",
       " '__init__.py',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('../src')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86690d39d28a98903103ee75e9cc8ef3c223c6291feb93f8e24b94a6d4a9c844"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('lift-splat-shoot': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
